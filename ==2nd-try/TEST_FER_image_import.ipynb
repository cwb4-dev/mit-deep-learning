{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kPhcoGIonmqoyhqZqGvdHmoajvI43_DW",
      "authorship_tag": "ABX9TyPdNS3DWgrXn0xnsEjuu+k+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwb4-dev/MIT-ADSP-Capstone/blob/main/TEST_FER_image_import.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qztrQJX2xFjY"
      },
      "outputs": [],
      "source": [
        "gdrive_path =   \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "dir_path =      \"2023-MIT-ADSP/FER-Project/\"\n",
        "image_path =    \"==Facial_emotion_images.zip\""
      ]
    },
    {
      "metadata": {
        "id": "g1zQ8974DmxB"
      },
      "cell_type": "markdown",
      "source": [
        "## **Import libraries**"
      ]
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "0O1OzQ0JDmxB"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "#import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import (Dense, Input, Dropout,\n",
        "                          GlobalAveragePooling2D, Flatten,\n",
        "                          Conv2D, BatchNormalization,\n",
        "                          Activation, MaxPooling2D, LeakyReLU)\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras import regularizers\n",
        "import keras\n",
        "from keras.callbacks import (ModelCheckpoint, CSVLogger, TensorBoard,\n",
        "                             EarlyStopping, ReduceLROnPlateau)\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import plot_model\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sMfr4tK04C0o"
      },
      "outputs": [],
      "source": [
        "# Storing the path of the data file from the Google drive\n",
        "import zipfile\n",
        "# path = f'/content/drive/MyDrive/Facial_emotion_images.zip'\n",
        "# path = f'/content/drive/MyDrive/==Facial_emotion_images.zip'\n",
        "\n",
        "path = gdrive_path + dir_path + image_path\n",
        "\n",
        "# The data is provided as a zip file so we need to extract the files from the zip file\n",
        "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TalL_1Qr-9Qz",
        "outputId": "f5c2af68-e64f-4f07-aa92-c9f3539ccf97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20214 total jpeg files\n",
            "\n",
            "Training dataset -- 15109 jpeg files\n",
            "3978 neutral images\n",
            "3982 sad images\n",
            "3173 surprise images\n",
            "3976 happy images\n",
            "\n",
            "Test dataset -- 128 jpeg files\n",
            "32 neutral images\n",
            "32 sad images\n",
            "32 surprise images\n",
            "32 happy images\n",
            "\n",
            "Validation dataset -- 4977 jpeg files\n",
            "1216 neutral images\n",
            "1139 sad images\n",
            "797 surprise images\n",
            "1825 happy images\n",
            "\n",
            "\n",
            "CPU times: user 25.9 ms, sys: 25.7 ms, total: 51.6 ms\n",
            "Wall time: 50.1 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "main_folder = \"/content/Facial_emotion_images/\"\n",
        "train_folder = main_folder + \"train/\"\n",
        "test_folder = main_folder + \"test/\"\n",
        "validation_folder = main_folder + \"validation/\"\n",
        "\n",
        "print(f'{sum([len(files) for r, d, files in os.walk(main_folder)])} total jpeg files')\n",
        "\n",
        "print(f'\\nTraining dataset -- {sum([len(files) for r, d, files in os.walk(train_folder)])} jpeg files')\n",
        "for expression in os.listdir(train_folder):\n",
        "    print(str(len(os.listdir(train_folder + expression))) + \" \" + expression + \" images\")\n",
        "\n",
        "print(f'\\nTest dataset -- {sum([len(files) for r, d, files in os.walk(test_folder)])} jpeg files')\n",
        "for expression in os.listdir(test_folder):\n",
        "    print(str(len(os.listdir(test_folder + expression))) + \" \" + expression + \" images\")\n",
        "\n",
        "print(f'\\nValidation dataset -- {sum([len(files) for r, d, files in os.walk(validation_folder)])} jpeg files')\n",
        "for expression in os.listdir(validation_folder):\n",
        "    print(str(len(os.listdir(validation_folder + expression))) + \" \" + expression + \" images\")\n",
        "print(\"\\n\")"
      ]
    }
  ]
}